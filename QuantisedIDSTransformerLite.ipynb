{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import random\n",
    "\n",
    "# Import quantization modules\n",
    "import torch.quantization\n",
    "from torch.quantization import QuantStub, DeQuantStub, fuse_modules\n",
    "from torch.quantization.qconfig import QConfig\n",
    "from torch.quantization import prepare_qat, convert\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV data into a DataFrame\n",
    "\n",
    "data_path = \"../data/data.csv\"\n",
    "columns = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', \n",
    "           'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', \n",
    "           'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', \n",
    "           'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', \n",
    "           'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', \n",
    "           'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', \n",
    "           'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', \n",
    "           'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', \n",
    "           'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label']\n",
    "\n",
    "df = pd.read_csv(data_path, header=None, names=columns)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will classify two different type of data, categorical and continous. This is because each type of data have \n",
    "different way of encoding it. So we will encode it differently, then concat it to create a token that represent a row of\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['protocol_type', 'service', 'flag', 'land', 'logged_in', 'is_host_login', 'is_guest_login']\n",
    "continuous_cols = [col for col in df.columns if col not in categorical_cols + ['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For continuous data, we will use normalisation \n",
    "scaler = StandardScaler()\n",
    "df_cont = pd.DataFrame(scaler.fit_transform(df[continuous_cols]), columns=continuous_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For categorical data, since they r text, we will use label encoder\n",
    "df_cat = df[categorical_cols].copy()\n",
    "cat_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_cat[col] = le.fit_transform(df_cat[col].astype(str))\n",
    "    cat_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the label\n",
    "# Process target labels: first remove trailing punctuation if any (e.g., \"normal.\" -> \"normal\")\n",
    "df['label'] = df['label'].str.replace(r'\\W+$', '', regex=True)\n",
    "target_labels = ['back', 'buffer_overflow', 'ftp_write', 'guess_passwd', 'imap', 'ipsweep', 'land', \n",
    "                 'loadmodule', 'multihop', 'neptune', 'nmap', 'normal', 'perl', 'phf', 'pod', 'portsweep', \n",
    "                 'rootkit', 'satan', 'smurf', 'spy', 'teardrop', 'warezclient', 'warezmaster']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label encoder for targets\n",
    "target_le = LabelEncoder()\n",
    "target_le.fit(target_labels)\n",
    "df['label_enc'] = target_le.transform(df['label'])\n",
    "print(target_le.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine continuous and categorical features\n",
    "df_features = pd.concat([df_cont, df_cat], axis=1)\n",
    "print(\"Processed features shape:\", df_features.shape)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My intention is using a transformer that have similar structure to BERT. This is because the model will have an attention layer to learn the semantic relationship between packets. The sliding allows\n",
    "use to look at a range of packets in sequence, and look if there is suspicious packets in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 100\n",
    "class SlidingWindowDataset(Dataset):\n",
    "    def __init__(self, features, labels, window_size):\n",
    "        \"\"\"\n",
    "        features: numpy array of shape (num_rows, num_features)\n",
    "        labels: numpy array of shape (num_rows,)\n",
    "        window_size: int, number of rows per window\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.window_size = window_size\n",
    "        self.num_samples = len(features) - window_size + 1  # number of sliding windows\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Extract a window of consecutive rows on the fly\n",
    "        window = self.features[idx : idx + self.window_size]\n",
    "        # For simplicity, we use the label of the last row in the window. It means that if there is a bad packet in the end of the sequence,\n",
    "        #the model will immediately flag entire sequence as bad as soon as a bad packet comes in\n",
    "        label = self.labels[idx + self.window_size - 1]\n",
    "        return torch.tensor(window, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Get the preprocessed feature and label arrays\n",
    "features_np = df_features.values.astype(np.float32)\n",
    "labels_np = df['label_enc'].values.astype(np.int64)\n",
    "print(\"Original features shape:\", features_np.shape)\n",
    "print(\"Original labels shape:\", labels_np.shape)\n",
    "\n",
    "# Create the sliding window dataset\n",
    "dataset = SlidingWindowDataset(features_np, labels_np, WINDOW_SIZE)\n",
    "print(\"Sliding window dataset length:\", len(dataset))\n",
    "\n",
    "# Split the dataset into training and test sets using random_split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) #originally batch_size = 32\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PacketTransformer(nn.Module):\n",
    "#     def __init__(self, input_dim, embed_dim, num_layers, num_heads, window_size, num_classes):\n",
    "#         super(PacketTransformer, self).__init__()\n",
    "#         self.window_size = window_size\n",
    "        \n",
    "#         # Project the input token (each row) into an embedding\n",
    "#         self.input_proj = nn.Linear(input_dim, embed_dim)\n",
    "        \n",
    "#         # [CLS] token embedding (learnable)\n",
    "#         self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "        \n",
    "#         # Positional embeddings: one per token in the window (+1 for [CLS])\n",
    "#         self.pos_embedding = nn.Parameter(torch.randn(window_size + 1, embed_dim))\n",
    "        \n",
    "#         # Transformer encoder layers\n",
    "#         encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=0.1)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "#         # Classification head\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(embed_dim, embed_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(embed_dim, num_classes)\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         x: tensor of shape [batch, window_size, input_dim]\n",
    "#         \"\"\"\n",
    "#         batch_size = x.size(0)\n",
    "#         # Project each token\n",
    "#         tokens = self.input_proj(x)  # [batch, window_size, embed_dim]\n",
    "        \n",
    "#         # Prepend [CLS] token for each sample in the batch\n",
    "#         cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # [batch, 1, embed_dim]\n",
    "#         tokens = torch.cat([cls_tokens, tokens], dim=1)  # [batch, window_size+1, embed_dim]\n",
    "        \n",
    "#         # Add positional embedding\n",
    "#         tokens = tokens + self.pos_embedding.unsqueeze(0)\n",
    "        \n",
    "#         # Transformer expects shape: [seq_len, batch, embed_dim]\n",
    "#         tokens = tokens.transpose(0, 1)\n",
    "#         transformer_out = self.transformer_encoder(tokens)\n",
    "        \n",
    "#         # Use [CLS] token output for classification (first token)\n",
    "#         cls_out = transformer_out[0]  # [batch, embed_dim]\n",
    "#         logits = self.classifier(cls_out)\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, num_layers):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        # Create transformer with batch_first=True for easier handling\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, \n",
    "            nhead=num_heads, \n",
    "            dropout=0.1, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.transformer_encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizablePacketTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_layers, num_heads, window_size, num_classes):\n",
    "        super(QuantizablePacketTransformer, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        # Quantization stubs\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "        \n",
    "        # Input projection - will be quantized\n",
    "        self.input_proj = nn.Linear(input_dim, embed_dim)\n",
    "        \n",
    "        # Parameters - will not be quantized\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(window_size + 1, embed_dim))\n",
    "        \n",
    "        # Transformer block - will not be quantized\n",
    "        self.transformer_block = TransformerBlock(embed_dim, num_heads, num_layers)\n",
    "        \n",
    "        # Classification head - will be quantized\n",
    "        self.fc1 = nn.Linear(embed_dim, embed_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(embed_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Quantize input\n",
    "        x = self.quant(x)\n",
    "        \n",
    "        # Process input projection (quantized)\n",
    "        batch_size = x.size(0)\n",
    "        tokens = self.input_proj(x)  # [batch, window_size, embed_dim]\n",
    "        \n",
    "        # Dequantize before non-quantizable operations\n",
    "        tokens = self.dequant(tokens)\n",
    "        \n",
    "        # Non-quantized operations\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "        tokens = torch.cat([cls_tokens, tokens], dim=1)\n",
    "        tokens = tokens + self.pos_embedding.unsqueeze(0)\n",
    "        \n",
    "        # Pass through transformer (non-quantized)\n",
    "        transformer_out = self.transformer_block(tokens)\n",
    "        cls_out = transformer_out[:, 0, :]  # Get CLS token output\n",
    "        \n",
    "        # Requantize for classification head\n",
    "        cls_out = self.quant(cls_out)\n",
    "        \n",
    "        # Classification head (quantized)\n",
    "        x = self.fc1(cls_out)\n",
    "        x = self.relu(x)\n",
    "        logits = self.fc2(x)\n",
    "        \n",
    "        # Final dequantization\n",
    "        logits = self.dequant(logits)\n",
    "        return logits\n",
    "    \n",
    "    def fuse_model(self):\n",
    "        \"\"\"Fuse operations for better quantization performance\"\"\"\n",
    "        try:\n",
    "            # Try both import paths for compatibility with different PyTorch versions\n",
    "            try:\n",
    "                from torch.quantization import fuse_modules\n",
    "            except ImportError:\n",
    "                from torch.ao.quantization import fuse_modules\n",
    "            \n",
    "            fuse_modules(self, ['fc1', 'relu'], inplace=True)\n",
    "            print(\"Fusion successful\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fusion failed: {e}. Continuing without fusion.\")\n",
    "    \n",
    "    def set_qconfig(self):\n",
    "        \"\"\"Custom qconfig setup that excludes transformer layers\"\"\"\n",
    "        qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "        \n",
    "        # Set qconfig for the whole model\n",
    "        self.qconfig = qconfig\n",
    "        \n",
    "        # Remove qconfig from transformer block (it doesn't support quantization well)\n",
    "        self.transformer_block.qconfig = None\n",
    "        \n",
    "        # Make sure parameters inside transformer are also without qconfig\n",
    "        for module in self.transformer_block.modules():\n",
    "            module.qconfig = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_for_qat(model, device):\n",
    "    # Step 1: Start with model on CPU\n",
    "    model = model.cpu()\n",
    "    \n",
    "    # Step 2: Fuse layers where possible\n",
    "    model.fuse_model()\n",
    "    \n",
    "    # Step 3: Set quantization backend\n",
    "    torch.backends.quantized.engine = 'fbgemm'  # Use 'qnnpack' for ARM processors\n",
    "    \n",
    "    # Step 4: Configure which parts to quantize\n",
    "    qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "    \n",
    "    # Default configuration for the model\n",
    "    model.qconfig = qconfig\n",
    "    \n",
    "    # Explicitly exclude transformer and parameters from quantization\n",
    "    model.transformer_block.qconfig = None\n",
    "    for module in model.transformer_block.modules():\n",
    "        module.qconfig = None\n",
    "    \n",
    "    # Step 5: Prepare the model for QAT\n",
    "    try:\n",
    "        torch.quantization.prepare_qat(model, inplace=True)\n",
    "        print(\"QAT preparation successful\")\n",
    "    except Exception as e:\n",
    "        print(f\"QAT preparation failed: {e}\")\n",
    "        \n",
    "    # Step 6: Move to the training device\n",
    "    return model.to(device)\n",
    "\n",
    "# Initialize and prepare the model\n",
    "input_dim = dataset.features.shape[-1]\n",
    "embed_dim = 16 #16\n",
    "num_layers = 1\n",
    "num_heads = 2\n",
    "num_classes = len(target_labels)\n",
    "num_epochs = 30\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Create the model\n",
    "model = QuantizablePacketTransformer(\n",
    "    input_dim=input_dim, \n",
    "    embed_dim=embed_dim, \n",
    "    num_layers=num_layers,\n",
    "    num_heads=num_heads, \n",
    "    window_size=WINDOW_SIZE, \n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_qat(model, device)\n",
    "\n",
    "# Set up training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6) #1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_epoch(model, loader, criterion, optimizer, device):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     # Wrap loader with tqdm for progress bar\n",
    "#     for batch_X, batch_y in tqdm(loader, desc=\"Training\", leave=False):\n",
    "#         batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         logits = model(batch_X)\n",
    "#         loss = criterion(logits, batch_y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item() * batch_X.size(0)\n",
    "#     return running_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_qat(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    processed_batches = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Move data to the correct device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss (make sure to use .item() to get the scalar value)\n",
    "        total_loss += loss.item()\n",
    "        processed_batches += 1\n",
    "        \n",
    "        # Print progress\n",
    "        # if batch_idx % 10 == 0:\n",
    "        #     print(f'Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Return average loss\n",
    "    return total_loss / processed_batches if processed_batches > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Wrap loader with tqdm for progress bar during evaluation\n",
    "    for batch_X, batch_y in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        logits = model(batch_X)\n",
    "        loss = criterion(logits, batch_y)\n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == batch_y).sum().item()\n",
    "        # Collect predictions and true labels for confusion matrix\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "        \n",
    "    avg_loss = running_loss / len(loader.dataset)\n",
    "    avg_acc = correct / len(loader.dataset)\n",
    "    return avg_loss, avg_acc, all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs+1):\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "    train_loss = train_with_qat(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, all_labels, all_preds = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colour scale is currently a bit strange\n",
    "\n",
    "def compute_confusion_matrix(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            logits = model(batch_X)\n",
    "            preds = logits.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "    return all_labels, all_preds\n",
    "\n",
    "# Compute confusion matrix on test data\n",
    "true_labels, pred_labels = compute_confusion_matrix(model, test_loader, device)\n",
    "cm = confusion_matrix(all_labels, all_preds, labels=list(range(len(target_labels))))\n",
    "\n",
    "# Create a larger figure\n",
    "fig, ax = plt.subplots(figsize=(12, 10))  \n",
    "\n",
    "# Pass 'ax=ax' to plot the confusion matrix on this figure\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_labels)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical', ax=ax)\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()  # Helps reduce label overlap\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
